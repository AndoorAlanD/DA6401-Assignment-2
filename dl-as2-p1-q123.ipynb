{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport wandb\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import wandb\nimport os\n\nos.environ['WANDB_API_KEY'] = '1ffc33d77af0fd022201ec32b81cd0e92cd75821'\nwandb.login()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sweep_config = {\n    'method': 'bayes', \n    'metric': {\n      'name': 'val_accuracy',\n      'goal': 'maximize'   \n    },\n    'parameters': {\n        'kernel_size':{\n            'values': [[3,3,3,3,3], [3,5,5,7,7], [7,7,5,5,3]]\n        },\n        'num_epochs':{\n            'values': [10]\n        },\n        'dropout': {\n            'values': [0, 0.2, 0.3]\n        },\n        'lr': {\n            'values': [0.0001, 0.001]\n        },\n        'activation': {\n            'values': ['ReLU', 'GELU', 'SiLU', 'Mish']\n        },\n        'optimizer': {\n            'values': ['adam', 'nadam']\n        },\n        'batch_norm':{\n            'values': ['true','false']\n        },\n        'filt_org':{\n            'values': ['same','double','half']\n        },\n        'num_filters': {\n            'values': [32,64]\n        },\n        'data_aug': {\n            'values': ['true','false']\n        },\n        'batch_size': {\n            'values': [32, 64, 128]\n        },\n        'num_dense':{\n            'values': [64, 128, 256]\n        }\n    }\n}\n\n\nsweep_id = wandb.sweep(sweep=sweep_config, project='DL_A2')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self, config, num_classes=10):\n        super(CNN, self).__init__()\n        self.config = config\n        self.num_epochs = config.num_epochs\n\n        self.to(device)\n\n        self.build_transforms()\n        self.prepare_data()\n        self.build_model(num_classes)\n        self.build_training_utils()\n\n    \n    def build_transforms(self):\n        base_transform = [\n            transforms.Resize((256, 256)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=(0.5,), std=(0.5,))\n        ]\n        \n        augmented_transform = [\n            transforms.Resize((256, 256)),\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomVerticalFlip(),\n            transforms.RandomRotation(20),\n            transforms.ColorJitter(),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=(0.5,), std=(0.5,))\n        ]\n        \n        self.transform = transforms.Compose(base_transform)\n        self.transform_aug = transforms.Compose(augmented_transform)\n\n    def prepare_data(self):\n        train_transform = self.transform_aug if self.config.data_aug == 'true' else self.transform\n\n        self.train_dataset = torchvision.datasets.ImageFolder(root='/kaggle/input/dl-assignment-2/inaturalist_12K/train',transform=train_transform)\n        self.train_dataset, self.val_dataset = torch.utils.data.random_split(self.train_dataset, [7999, 2000])\n\n        self.train_loader = torch.utils.data.DataLoader(self.train_dataset, batch_size=self.config.batch_size, shuffle=True)\n        self.val_loader = torch.utils.data.DataLoader(self.val_dataset, batch_size=self.config.batch_size, shuffle=True)\n\n    def build_model(self, num_classes):\n        if self.config.filt_org == 'half':\n            self.filt_size = 0.5\n        elif self.config.filt_org == 'double':\n            self.filt_size = 2\n        else:\n            self.filt_size = 1\n\n        \n        inp_fl = 3\n        out_fl = self.config.num_filters\n        self.convL1 = nn.Conv2d(inp_fl, out_fl, self.config.kernel_size[0], stride=1, padding=1)\n        self.batN1 = nn.BatchNorm2d(out_fl)\n\n        inp_fl = out_fl\n        out_fl = int(out_fl * self.filt_size)\n        self.convL2 = nn.Conv2d(inp_fl, out_fl, self.config.kernel_size[1], stride=1, padding=1)\n        self.batN2 = nn.BatchNorm2d(out_fl)\n\n        inp_fl = out_fl\n        out_fl = int(out_fl * self.filt_size)\n        self.convL3 = nn.Conv2d(inp_fl, out_fl, self.config.kernel_size[2], stride=1, padding=1)\n        self.batN3 = nn.BatchNorm2d(out_fl)\n\n        inp_fl = out_fl\n        out_fl = int(out_fl * self.filt_size)\n        self.convL4 = nn.Conv2d(inp_fl, out_fl, self.config.kernel_size[3], stride=1, padding=1)\n        self.batN4 = nn.BatchNorm2d(out_fl)\n\n        inp_fl = out_fl\n        out_fl = int(out_fl * self.filt_size)\n        self.convL5 = nn.Conv2d(inp_fl, out_fl, self.config.kernel_size[4], stride=1, padding=1)\n        self.batN5 = nn.BatchNorm2d(out_fl)\n\n        self.maxPool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n\n        img_size = 256\n        for k in self.config.kernel_size:\n            img_size = (img_size - k + 3) // 2\n\n        self.x_shape = out_fl * img_size * img_size\n\n        self.f_Conn = nn.Linear(self.x_shape, self.config.num_dense)\n        self.batN_de = nn.BatchNorm1d(self.config.num_dense)\n        self.dropout = nn.Dropout(p=self.config.dropout)\n        self.opL = nn.Linear(self.config.num_dense, num_classes)\n    \n        if self.config.activation == 'ReLU':\n            self.activation = F.relu\n        elif self.config.activation == 'SiLU':\n            self.activation = F.silu\n        elif self.config.activation == 'GELU':\n            self.activation = F.gelu\n        else:\n            self.activation = F.mish\n\n    def build_training_utils(self):\n        self.criterion = nn.CrossEntropyLoss()\n        optimizers = {\n            'adam': optim.Adam,\n            'nadam': optim.NAdam\n        }\n        self.optimizer = optimizers[self.config.optimizer](self.parameters(), lr=self.config.lr)\n\n    def forward(self, x):\n        x=self.activation(self.convL1(x))\n        y=self.config.batch_norm\n        if y== 'true': x = self.batN1(x)\n        x = self.maxPool(x)\n\n        x = self.activation(self.convL2(x))\n        if y== 'true': x = self.batN2(x)\n        x = self.maxPool(x)\n\n        x = self.activation(self.convL3(x))\n        if y== 'true': x = self.batN3(x)\n        x = self.maxPool(x)\n\n        x = self.activation(self.convL4(x))\n        if y== 'true': x = self.batN4(x)\n        x = self.maxPool(x)\n\n        x = self.activation(self.convL5(x))\n        if y== 'true': x = self.batN5(x)\n        x = self.maxPool(x)\n\n        x = x.view(-1, self.x_shape)\n        x = self.activation(self.f_Conn(x))\n        if y== 'true': x = self.batN_de(x)\n        x = self.dropout(x)\n        y_pred = self.opL(x)\n        return y_pred\n\n    def accuracy(self, loader):\n        accurate, total, loss = 0, 0, 0\n        self.eval()\n        with torch.no_grad():\n            for x, y_act in loader:\n                x, y_act=x.to(device), y_act.to(device)\n                result=self(x)\n                batch_size=y_act.size(0)\n                total+=batch_size\n                _, y_pred=torch.max(result.data, 1)\n                accurate+=torch.sum(y_pred==y_act).item()\n                batch_loss=self.criterion(result, y_act).item()\n                loss +=batch_loss*batch_size\n\n        self.train()\n        return accurate/total, loss/total\n\n\n    def train_model(self):\n        total_size = len(self.train_loader)\n        for epoch in range(self.num_epochs):\n            tr_loss = 0\n            accurate = 0\n            for i, (x, y_act) in enumerate(self.train_loader):\n                \n                x, y_act = x.to(device), y_act.to(device)\n                result = self(x)\n                loss = self.criterion(result, y_act)\n\n                y_pred = torch.argmax(result.data, dim=1)\n                accurate += torch.sum(y_pred == y_act).item()\n                \n                self.optimizer.zero_grad()\n                loss.backward()\n                self.optimizer.step()\n                tr_loss += loss.item()\n                if (i+1)%25 == 0:\n                    print(f\"Epoch [{epoch + 1}/{self.num_epochs}]| Step [{i + 1}/{total_size}]\")\n\n            tr_loss /= total_size\n            tr_acc = accurate / (total_size * self.config.batch_size)\n\n            val_acc, val_loss = self.accuracy(self.val_loader)\n\n            tr_acc*=100\n            val_acc*=100\n\n            print(\"Train Accuracy:\", tr_acc, \"\\nTrain Loss:\", tr_loss)\n            print(\"Validation Accuracy:\", val_acc, \"\\nValidation Loss:\", val_loss, \"\\n\")\n            wandb.log({'train_accuracy': tr_acc,'train_loss': tr_loss,'val_accuracy': val_acc,'val_loss': val_loss,})\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def main():\n    with wandb.init() as run:\n        config=wandb.config\n\n        bn=int(config.batch_norm == 'true')\n        da=int(config.data_aug == 'true')\n        ks=''.join(str(config.kernel_size[i]) for i in range(0, 5))\n\n        wandb.run.name = (\n            f\"{config.activation}-{config.optimizer}-bn_{bn}-da_{da}-do_{config.dropout}-bs_{config.batch_size}\"\n            f\"-lr_{config.lr}-f_{config.num_filters}-{config.filt_org}-ks_{ks}-fc_{config.num_dense}\"\n        )\n        \n        model=CNN(config, num_classes=10).to(device)\n        model.train_model()\n\nwandb.agent(sweep_id, function=main)\nwandb.finish() \n#pvfkxl7z","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}