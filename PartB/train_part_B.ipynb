{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11458118,"sourceType":"datasetVersion","datasetId":7179445}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%writefile train_partB.py\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms, models\nimport wandb\nimport argparse\nimport os\n\nos.environ['WANDB_API_KEY'] = '1ffc33d77af0fd022201ec32b81cd0e92cd75821'\nwandb.login()\n\nclass ResNetFineTuner(nn.Module):\n    def __init__(self, config, num_classes=10):\n        super(ResNetFineTuner, self).__init__()\n        self.config = config\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n        self.model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n        for param in self.model.parameters():\n            param.requires_grad = False\n\n        modules = []\n        if config.dropout > 0:\n            modules.append(nn.Dropout(config.dropout))\n        modules.append(nn.Linear(self.model.fc.in_features, config.num_dense))\n\n        if config.batch_norm == \"true\":\n            modules.append(nn.BatchNorm1d(config.num_dense))\n\n        modules.append(self.get_activation(config.activation))\n        modules.append(nn.Linear(config.num_dense, num_classes))\n        self.model.fc = nn.Sequential(*modules)\n\n        for param in self.model.fc.parameters():\n            param.requires_grad = True\n\n        self.model = self.model.to(self.device)\n        self.criterion = nn.CrossEntropyLoss()\n        if config.optimizer == \"adam\":\n            self.optimizer = optim.Adam(self.model.parameters(), lr=config.lr)\n        elif config.optimizer == \"nadam\":\n            self.optimizer = optim.NAdam(self.model.parameters(), lr=config.lr)\n\n        self.train_loader, self.val_loader = self.get_data_loaders()\n\n    def get_activation(self, name):\n        return {\n            \"ReLU\": nn.ReLU(),\n            \"GELU\": nn.GELU(),\n            \"SiLU\": nn.SiLU(),\n            \"Mish\": nn.Mish()\n        }.get(name, nn.ReLU())\n\n    def get_data_loaders(self):\n        mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n        train_transforms = [transforms.Resize((224, 224))]\n        if self.config.data_aug == \"true\":\n            train_transforms += [transforms.RandomHorizontalFlip(), transforms.RandomRotation(15)]\n        train_transforms += [transforms.ToTensor(), transforms.Normalize(mean, std)]\n\n        val_transforms = transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean, std),\n        ])\n\n        train_dataset = datasets.ImageFolder(\"/kaggle/input/dl-assignment-2/inaturalist_12K/train\",\n                                             transform=transforms.Compose(train_transforms))\n        val_dataset = datasets.ImageFolder(\"/kaggle/input/dl-assignment-2/inaturalist_12K/val\",\n                                           transform=val_transforms)\n\n        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True, num_workers=2)\n        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size, shuffle=False, num_workers=2)\n\n        return train_loader, val_loader\n\n    def train_model(self, num_epochs=10):\n        for epoch in range(num_epochs):\n            self.model.train()\n            running_loss, correct, total = 0, 0, 0\n            for images, labels in self.train_loader:\n                images, labels = images.to(self.device), labels.to(self.device)\n                self.optimizer.zero_grad()\n                outputs = self.model(images)\n                loss = self.criterion(outputs, labels)\n                loss.backward()\n                self.optimizer.step()\n\n                running_loss += loss.item() * images.size(0)\n                _, preds = torch.max(outputs, 1)\n                correct += (preds == labels).sum().item()\n                total += labels.size(0)\n\n            train_loss = running_loss / total\n            train_acc = correct / total\n\n            val_loss, val_acc = self.validate()\n            wandb.log({\"train_loss\": train_loss, \"train_acc\": train_acc * 100, \"val_loss\": val_loss, \"val_acc\": val_acc * 100})\n\n            print(f\"Epoch {epoch + 1}: Train Acc: {train_acc * 100:.2f}%, Val Acc: {val_acc * 100:.2f}%, Val Loss: {val_loss:.4f}\")\n\n        torch.save(self.model.state_dict(), \"finetuned_resnet50.pth\")\n\n    def validate(self):\n        self.model.eval()\n        val_loss = 0\n        val_correct, val_total = 0, 0\n        with torch.no_grad():\n            for images, labels in self.val_loader:\n                images, labels = images.to(self.device), labels.to(self.device)\n                outputs = self.model(images)\n                loss = self.criterion(outputs, labels)\n                val_loss += loss.item() * images.size(0)\n                _, preds = torch.max(outputs, 1)\n                val_correct += (preds == labels).sum().item()\n                val_total += labels.size(0)\n\n        return val_loss / val_total, val_correct / val_total\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser(description=\"Fine-tune ResNet50 with configurable options and W&B logging\")\n    parser.add_argument(\"-wp\", \"--wandb_project\", type=str, required=True)\n    parser.add_argument(\"-we\", \"--wandb_entity\", type=str, required=True)\n    parser.add_argument(\"--dropout\", type=float, default=0.3)\n    parser.add_argument(\"--lr\", type=float, default=0.001)\n    parser.add_argument(\"--activation\", type=str, default=\"Mish\", choices=[\"ReLU\", \"GELU\", \"SiLU\", \"Mish\"])\n    parser.add_argument(\"--optimizer\", type=str, default=\"adam\", choices=[\"adam\", \"nadam\"])\n    parser.add_argument(\"--batch_norm\", type=str, default=\"true\", choices=[\"true\", \"false\"])\n    parser.add_argument(\"--data_aug\", type=str, default=\"true\", choices=[\"true\", \"false\"])\n    parser.add_argument(\"--batch_size\", type=int, default=128)\n    parser.add_argument(\"--num_dense\", type=int, default=128)\n    parser.add_argument(\"--epochs\", type=int, default=10)\n    # return vars(parser.parse_args())\n    return parser.parse_args()\n\n\ndef main():\n    # args = parse_args()\n\n    # wandb.init(project=args[\"wandb_project\"], entity=args[\"wandb_entity\"], config=args)\n    args = parse_args()\n\n    wandb.init(project=args.wandb_project, entity=args.wandb_entity, config=vars(args))\n    wandb.run.name = (\n        f\"{args.optimizer}-{args.activation}-bn_{args.batch_norm}-da_{args.data_aug}-do_{args.dropout}\"\n        f\"-bs_{args.batch_size}-lr_{args.lr}-fc_{args.num_dense}\"\n    )\n\n    model = ResNetFineTuner(args)\n    model.train_model(num_epochs=args.epochs)\n    wandb.finish()\n\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:38:11.578124Z","iopub.execute_input":"2025-04-19T15:38:11.578398Z","iopub.status.idle":"2025-04-19T15:38:11.585274Z","shell.execute_reply.started":"2025-04-19T15:38:11.578380Z","shell.execute_reply":"2025-04-19T15:38:11.584681Z"}},"outputs":[{"name":"stdout","text":"Overwriting train_partB.py\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"!python train_partB.py --wandb_entity alandandoor-iit-madras --wandb_project DL_A2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:38:13.631447Z","iopub.execute_input":"2025-04-19T15:38:13.632150Z","iopub.status.idle":"2025-04-19T15:51:07.407858Z","shell.execute_reply.started":"2025-04-19T15:38:13.632125Z","shell.execute_reply":"2025-04-19T15:51:07.407041Z"}},"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malandandoor\u001b[0m (\u001b[33malandandoor-iit-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.6\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250419_153817-nalnlwew\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrich-pond-585\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/alandandoor-iit-madras/DL_A2\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/alandandoor-iit-madras/DL_A2/runs/nalnlwew\u001b[0m\nEpoch 1: Train Acc: 65.27%, Val Acc: 72.75%, Val Loss: 0.7989\nEpoch 2: Train Acc: 71.38%, Val Acc: 72.15%, Val Loss: 0.7944\nEpoch 3: Train Acc: 72.32%, Val Acc: 74.40%, Val Loss: 0.7519\nEpoch 4: Train Acc: 72.93%, Val Acc: 74.45%, Val Loss: 0.7266\nEpoch 5: Train Acc: 74.60%, Val Acc: 75.60%, Val Loss: 0.7312\nEpoch 6: Train Acc: 74.69%, Val Acc: 75.20%, Val Loss: 0.7386\nEpoch 7: Train Acc: 75.64%, Val Acc: 75.70%, Val Loss: 0.7047\nEpoch 8: Train Acc: 75.43%, Val Acc: 75.05%, Val Loss: 0.7094\nEpoch 9: Train Acc: 76.21%, Val Acc: 76.40%, Val Loss: 0.6890\nEpoch 10: Train Acc: 76.01%, Val Acc: 76.75%, Val Loss: 0.6995\n\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n\u001b[34m\u001b[1mwandb\u001b[0m: \n\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà\n\u001b[34m\u001b[1mwandb\u001b[0m: train_loss ‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ\n\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ‚ñÇ‚ñÅ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñà\n\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss ‚ñà‚ñà‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÇ\n\u001b[34m\u001b[1mwandb\u001b[0m: \n\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 76.0076\n\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.68603\n\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 76.75\n\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 0.69952\n\u001b[34m\u001b[1mwandb\u001b[0m: \n\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33madam-Mish-bn_true-da_true-do_0.3-bs_128-lr_0.001-fc_128\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/alandandoor-iit-madras/DL_A2/runs/nalnlwew\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/alandandoor-iit-madras/DL_A2\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250419_153817-nalnlwew/logs\u001b[0m\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"!python train_partB.py --wandb_entity alandandoor-iit-madras --wandb_project DL_A2 --dropout 0.2 --lr 0.0001 --activation Mish --optimizer nadam --batch_norm true --data_aug true --batch_size 64 --num_dense 128\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T15:51:07.409435Z","iopub.execute_input":"2025-04-19T15:51:07.409713Z","iopub.status.idle":"2025-04-19T16:03:26.554437Z","shell.execute_reply.started":"2025-04-19T15:51:07.409690Z","shell.execute_reply":"2025-04-19T16:03:26.553679Z"}},"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malandandoor\u001b[0m (\u001b[33malandandoor-iit-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.6\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250419_155113-bklaspes\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcrimson-mountain-586\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/alandandoor-iit-madras/DL_A2\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/alandandoor-iit-madras/DL_A2/runs/bklaspes\u001b[0m\nEpoch 1: Train Acc: 56.96%, Val Acc: 70.65%, Val Loss: 1.0309\nEpoch 2: Train Acc: 68.08%, Val Acc: 72.90%, Val Loss: 0.8839\nEpoch 3: Train Acc: 70.94%, Val Acc: 73.40%, Val Loss: 0.8306\nEpoch 4: Train Acc: 71.79%, Val Acc: 73.85%, Val Loss: 0.7973\nEpoch 5: Train Acc: 72.75%, Val Acc: 73.70%, Val Loss: 0.7865\nEpoch 6: Train Acc: 73.05%, Val Acc: 75.20%, Val Loss: 0.7611\nEpoch 7: Train Acc: 73.30%, Val Acc: 74.65%, Val Loss: 0.7480\nEpoch 8: Train Acc: 74.25%, Val Acc: 75.15%, Val Loss: 0.7409\nEpoch 9: Train Acc: 74.21%, Val Acc: 75.45%, Val Loss: 0.7290\nEpoch 10: Train Acc: 74.26%, Val Acc: 75.40%, Val Loss: 0.7324\n\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n\u001b[34m\u001b[1mwandb\u001b[0m: \n\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ‚ñÅ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà\n\u001b[34m\u001b[1mwandb\u001b[0m: train_loss ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñà‚ñá‚ñà‚ñà‚ñà\n\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss ‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\u001b[34m\u001b[1mwandb\u001b[0m: \n\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 74.25743\n\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.76562\n\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 75.4\n\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 0.73237\n\u001b[34m\u001b[1mwandb\u001b[0m: \n\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mnadam-Mish-bn_true-da_true-do_0.2-bs_64-lr_0.0001-fc_128\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/alandandoor-iit-madras/DL_A2/runs/bklaspes\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/alandandoor-iit-madras/DL_A2\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250419_155113-bklaspes/logs\u001b[0m\n","output_type":"stream"}],"execution_count":22}]}